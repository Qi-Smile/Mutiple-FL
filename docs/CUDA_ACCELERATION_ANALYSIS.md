# CUDA åŠ é€Ÿåˆ†ææŠ¥å‘Š

## æ¦‚è¿°

æœ¬æ–‡æ¡£åˆ†æå¤šæœåŠ¡å™¨è”é‚¦å­¦ä¹ ç³»ç»Ÿä¸­æ”»å‡»å’Œé˜²å¾¡æ–¹æ³•çš„ CUDA åŠ é€Ÿæƒ…å†µã€‚

---

## ğŸ¯ æ€»ä½“ç»“è®º

### âœ… å·²ä½¿ç”¨ CUDA çš„éƒ¨åˆ†
1. **å®¢æˆ·ç«¯è®­ç»ƒ**ï¼šå®Œå…¨åœ¨ GPU ä¸Šï¼ˆæ¨¡å‹ã€æ•°æ®ã€æ¢¯åº¦ï¼‰
2. **å®¢æˆ·ç«¯è¯„ä¼°**ï¼šå®Œå…¨åœ¨ GPU ä¸Š
3. **FLTrust Root Gradient è®¡ç®—**ï¼šåœ¨ GPU ä¸Šè®¡ç®—
4. **æ¢¯åº¦ç©ºé—´æ”»å‡»**ï¼šåœ¨ GPU ä¸Šæ‰§è¡Œï¼ˆæ“çºµ GPU ä¸Šçš„æ¢¯åº¦ï¼‰

### âŒ æœªä½¿ç”¨ CUDA çš„éƒ¨åˆ†ï¼ˆåœ¨ CPU ä¸Šï¼‰
1. **æ‰€æœ‰é˜²å¾¡èšåˆç®—æ³•**ï¼šGeometric Median, Krum, Median, FLTrust èšåˆç­‰
2. **æ‰€æœ‰å‚æ•°ç©ºé—´æ”»å‡»**ï¼šALIE, Adaptive ç­‰
3. **æ¨¡å‹å‚æ•°ä¼ è¾“å’Œå¤„ç†**ï¼šflatten/unflattenã€state_dict æ“ä½œ

---

## ğŸ“Š è¯¦ç»†åˆ†æ

### 1. å®¢æˆ·ç«¯è®­ç»ƒï¼ˆå®Œå…¨ GPU åŠ é€Ÿ âœ…ï¼‰

**ä»£ç ä½ç½®**ï¼š`multi_server_fl/client.py:124-150`

```python
def train_one_round(self):
    self.model.train()
    dataloader = self._train_dataloader()

    for epoch in range(self.config.local_epochs):
        for inputs, targets in dataloader:
            inputs = inputs.to(self.device)      # âœ… GPU
            targets = targets.to(self.device)     # âœ… GPU

            outputs = self.model(inputs)          # âœ… GPU è®¡ç®—
            loss = self.criterion(outputs, targets)  # âœ… GPU
            loss.backward()                       # âœ… GPU åå‘ä¼ æ’­

            # æ¢¯åº¦æ”»å‡»ï¼ˆå¦‚æœæ˜¯æ¶æ„å®¢æˆ·ç«¯ï¼‰
            if self.is_malicious and self.gradient_attack_fn is not None:
                self.gradient_attack_fn(self.model)  # âœ… GPU ä¸Šæ“çºµæ¢¯åº¦

            self.optimizer.step()                 # âœ… GPU ä¸Šæ›´æ–°å‚æ•°
```

**CUDA ä½¿ç”¨æƒ…å†µ**ï¼š
- âœ… æ¨¡å‹åœ¨ GPU ä¸Šï¼š`self.model.to(self.device)`
- âœ… æ•°æ®åœ¨ GPU ä¸Šï¼š`inputs.to(self.device)`
- âœ… æ¢¯åº¦åœ¨ GPU ä¸Šï¼šè‡ªåŠ¨ç”± PyTorch ç®¡ç†
- âœ… å‚æ•°æ›´æ–°åœ¨ GPU ä¸Šï¼šoptimizer çŠ¶æ€åœ¨ GPU

**æ€§èƒ½ç‰¹å¾**ï¼š
- å®Œå…¨åˆ©ç”¨ GPU å¹¶è¡Œè®¡ç®—
- æ—  CPU-GPU æ•°æ®ä¼ è¾“ç“¶é¢ˆï¼ˆé™¤äº† mini-batch åŠ è½½ï¼‰

---

### 2. æ¢¯åº¦ç©ºé—´æ”»å‡»ï¼ˆå®Œå…¨ GPU åŠ é€Ÿ âœ…ï¼‰

**ä»£ç ä½ç½®**ï¼š`multi_server_fl/attacks/client.py:42-106`

#### SignFlip æ”»å‡»
```python
def create_signflip_attack():
    def attack(model: nn.Module) -> None:
        for param in model.parameters():
            if param.grad is not None:
                param.grad.data = -param.grad.data  # âœ… GPU ä¸ŠåŸåœ°æ“ä½œ
    return attack
```

#### Noise æ”»å‡»
```python
def create_noise_attack(mean: float = 0.0, std: float = 0.1):
    def attack(model: nn.Module) -> None:
        for param in model.parameters():
            if param.grad is not None:
                noise = torch.randn_like(param.grad) * std + mean  # âœ… GPU ä¸Šç”Ÿæˆå™ªå£°
                param.grad.data = noise  # âœ… GPU ä¸Šæ›¿æ¢
    return attack
```

**CUDA ä½¿ç”¨æƒ…å†µ**ï¼š
- âœ… æ¢¯åº¦å·²ç»åœ¨ GPU ä¸Šï¼ˆç”±è®­ç»ƒäº§ç”Ÿï¼‰
- âœ… æ“ä½œç›´æ¥åœ¨ GPU ä¸Šæ‰§è¡Œï¼ˆåŸåœ°ä¿®æ”¹ï¼‰
- âœ… æ— éœ€ CPU-GPU æ•°æ®ä¼ è¾“

**æ€§èƒ½ç‰¹å¾**ï¼š
- æå¿«ï¼šO(å‚æ•°æ•°é‡)ï¼ŒGPU å¹¶è¡Œæ‰§è¡Œ
- å‡ ä¹é›¶å¼€é”€ï¼ˆç›¸æ¯”è®­ç»ƒæœ¬èº«ï¼‰

---

### 3. FLTrust Root Gradient è®¡ç®—ï¼ˆGPU åŠ é€Ÿ âœ…ï¼‰

**ä»£ç ä½ç½®**ï¼š`multi_server_fl/utils.py:466-496`

```python
def _compute_root_gradient_vector(
    model_builder, state_dict, root_loader, device, loss_fn
):
    model = model_builder().to(device)  # âœ… æ¨¡å‹åœ¨ GPU
    model.load_state_dict(state_dict)
    model.train()

    criterion = loss_fn or torch.nn.CrossEntropyLoss()

    for inputs, targets in root_loader:
        inputs = inputs.to(device)      # âœ… æ•°æ®åœ¨ GPU
        targets = targets.to(device)    # âœ… æ ‡ç­¾åœ¨ GPU
        outputs = model(inputs)          # âœ… GPU å‰å‘ä¼ æ’­
        loss = criterion(outputs, targets)  # âœ… GPU è®¡ç®—æŸå¤±
        loss.backward()                  # âœ… GPU åå‘ä¼ æ’­

    # æ”¶é›†æ¢¯åº¦å¹¶è½¬åˆ° CPU
    gradients = []
    for param in model.parameters():
        if param.grad is None:
            gradients.append(torch.zeros_like(param).reshape(-1))
        else:
            gradients.append(param.grad.detach().clone().reshape(-1))

    grad_vector = torch.cat(gradients).to(torch.float32).cpu()  # âŒ è½¬åˆ° CPU
    return grad_vector
```

**CUDA ä½¿ç”¨æƒ…å†µ**ï¼š
- âœ… Root æ•°æ®é›†çš„å‰å‘/åå‘ä¼ æ’­åœ¨ GPU ä¸Š
- âŒ æœ€ç»ˆæ¢¯åº¦å‘é‡è½¬åˆ° CPUï¼ˆä¸ºäº†åç»­èšåˆï¼‰

**æ€§èƒ½ç‰¹å¾**ï¼š
- Root æ•°æ®é›†é€šå¸¸å¾ˆå°ï¼ˆ1% çš„è®­ç»ƒæ•°æ®ï¼‰
- GPU è®¡ç®—éƒ¨åˆ†å¾ˆå¿«
- CPU è½¬æ¢å¼€é”€è¾ƒå°

---

### 4. é˜²å¾¡èšåˆç®—æ³•ï¼ˆCPU è®¡ç®— âŒï¼‰

#### Geometric Median (Weiszfeld's Algorithm)

**ä»£ç ä½ç½®**ï¼š`multi_server_fl/utils.py:220-261`

```python
def geometric_median_state_dicts(state_dicts, weights, max_iters=50, tol=1e-6):
    # âŒ æ‰€æœ‰æ“ä½œåœ¨ CPU ä¸Š
    flat_states = torch.stack([
        flatten_state_dict(state).to(torch.float64)  # CPU tensor
        for state in state_dicts
    ])

    weight_tensor = torch.tensor(weights, dtype=torch.float64)  # CPU
    median = (flat_states * weight_tensor.unsqueeze(1)).sum(dim=0)  # CPU

    for _ in range(max_iters):
        distances = torch.norm(flat_states - median, dim=1).clamp_min(eps)  # CPU
        inverted = weight_tensor / distances  # CPU
        # ... æ›´å¤š CPU è®¡ç®—

    return unflatten_state_dict(median.to(torch.float32), state_dicts[0])
```

**ä¸ºä»€ä¹ˆåœ¨ CPU ä¸Š**ï¼š
- æ¨¡å‹å‚æ•°ä» GPU å®¢æˆ·ç«¯æ”¶é›†æ—¶å·²ç»è½¬åˆ° CPUï¼š`client.get_model_state(to_cpu=True)`
- èšåˆç®—æ³•å¤„ç†å¤šä¸ªå®¢æˆ·ç«¯çš„å‚æ•°ï¼ˆå†…å­˜å ç”¨å¤§ï¼‰
- Weiszfeld è¿­ä»£ç®—æ³•ä¸é€‚åˆ GPU å¹¶è¡Œï¼ˆä¸²è¡Œè¿­ä»£ï¼‰

**æ€§èƒ½å½±å“**ï¼š
- å¯¹äºå°æ¨¡å‹ï¼ˆLeNet: ~44K å‚æ•°ï¼‰ï¼ŒCPU è®¡ç®—å¾ˆå¿«ï¼ˆ< 0.1 ç§’ï¼‰
- å¯¹äºå¤§æ¨¡å‹ï¼ˆResNet: ~11M å‚æ•°ï¼‰ï¼Œå¯èƒ½æˆä¸ºç“¶é¢ˆï¼ˆ~1-2 ç§’ï¼‰

#### Krum

**ä»£ç ä½ç½®**ï¼š`multi_server_fl/utils.py:361-432`

```python
def krum_aggregate(state_dicts, weights, num_malicious=0, multi_krum=False):
    # âŒ CPU è®¡ç®—
    vecs = torch.stack([
        flatten_state_dict(state).to(torch.float32)
        for state in state_dicts
    ])  # CPU tensor

    # Compute pairwise L2 distances
    distances = torch.cdist(vecs, vecs, p=2)  # âŒ CPUï¼Œ[n, n] è·ç¦»çŸ©é˜µ

    # Krum scoring
    scores = []
    for i in range(n):
        sorted_distances, _ = torch.sort(distances[i])  # âŒ CPU
        score = sorted_distances[1:n_select+1].sum()
        scores.append(score.item())

    # Select best update(s)
    best_idx = scores.index(min(scores))
    return clone_state_dict(state_dicts[best_idx])
```

**ä¸ºä»€ä¹ˆåœ¨ CPU ä¸Š**ï¼š
- éœ€è¦è®¡ç®— nÃ—n è·ç¦»çŸ©é˜µï¼ˆå¯¹äº 100 å®¢æˆ·ç«¯ï¼Œ10000 ä¸ªè·ç¦»ï¼‰
- æ’åºæ“ä½œä¸é€‚åˆ GPUï¼ˆå°è§„æ¨¡æ•°æ®ï¼‰

**æ€§èƒ½å½±å“**ï¼š
- è·ç¦»è®¡ç®—ï¼šO(nÂ² Ã— d)ï¼Œå…¶ä¸­ d = å‚æ•°æ•°é‡
- å¯¹äº 100 å®¢æˆ·ç«¯ + 11M å‚æ•°ï¼šçº¦ 1-2 ç§’

#### FLTrust èšåˆ

**ä»£ç ä½ç½®**ï¼š`multi_server_fl/utils.py:499-553`

```python
def fltrust_aggregate(initial_state, client_states, ...):
    # âŒ CPU è®¡ç®—
    update_matrix, base_vec = _compute_client_update_matrix(
        client_states, initial_state
    )  # CPU tensors

    root_grad = _compute_root_gradient_vector(...)  # è¿”å› CPU tensor
    root_norm = torch.norm(root_grad).clamp(min=1e-6)  # CPU

    if normalize_updates:
        update_norms = torch.norm(update_matrix, dim=1).clamp(min=1e-6)  # CPU
        scale = (root_norm / update_norms).clamp(max=10.0)  # CPU
        normalized_updates = update_matrix * scale.unsqueeze(1)  # CPU

    # Compute trust scores
    cos_sim = (normalized_updates @ root_grad) / (update_norms * root_norm)  # CPU
    trust_scores = torch.clamp(cos_sim, min=trust_threshold)  # CPU

    aggregated_update = (normalized_updates * trust_scores.unsqueeze(1)).sum(dim=0)  # CPU
    return unflatten_state_dict(aggregated_vec, client_states[0])
```

**ä¸ºä»€ä¹ˆåœ¨ CPU ä¸Š**ï¼š
- å®¢æˆ·ç«¯å‚æ•°å·²ç»åœ¨ CPU
- Root gradient è®¡ç®—åè½¬åˆ° CPU
- çŸ©é˜µä¹˜æ³•åœ¨ CPUï¼ˆä½†è§„æ¨¡ä¸å¤§ï¼Œé€šå¸¸ < 100 å®¢æˆ·ç«¯ï¼‰

**æ€§èƒ½å½±å“**ï¼š
- Root gradient è®¡ç®—ï¼šGPU åŠ é€Ÿï¼ˆå°æ•°æ®é›†ï¼Œå¿«ï¼‰
- èšåˆè®¡ç®—ï¼šCPUï¼ˆä½†çŸ©é˜µè¿ç®—ï¼Œè¾ƒå¿«ï¼‰
- æ€»ä½“ï¼šçº¦ 0.5-1 ç§’ï¼ˆå–å†³äºæ¨¡å‹å¤§å°ï¼‰

---

### 5. å‚æ•°ç©ºé—´æ”»å‡»ï¼ˆCPU è®¡ç®— âŒï¼‰

#### ALIE æ”»å‡»

**ä»£ç ä½ç½®**ï¼š`multi_server_fl/attacks/client.py:117-204`

```python
def alie_attack(client_states, malicious_ids, client_ids, initial_state, **kwargs):
    # âŒ CPU è®¡ç®—
    malicious_mask = torch.tensor([
        cid in malicious_ids for cid in client_ids
    ], dtype=torch.bool)  # CPU

    # Convert to update vectors
    initial_vec = flatten_state_dict(initial_state)  # CPU
    update_vecs = []
    for state in client_states:
        vec = flatten_state_dict(state)  # CPU
        update_vecs.append(vec - initial_vec)
    updates = torch.stack(update_vecs)  # CPU tensor

    # Compute statistics from benign updates
    benign = updates[~malicious_mask]  # CPU
    mean = benign.mean(dim=0)  # CPU
    std = benign.std(dim=0).clamp(min=1e-6)  # CPU

    # Calculate z_max
    z_max = torch.distributions.Normal(0, 1).icdf(torch.tensor(p))  # CPU

    # Craft malicious update
    malicious_update = mean + z_max * std  # CPU

    # Apply to malicious clients
    for cid, state in zip(client_ids, client_states):
        if cid in malicious_ids:
            attacked_vec = initial_vec + malicious_update  # CPU
            attacked_state = unflatten_state_dict(attacked_vec, state)  # CPU
            attacked_states.append(attacked_state)

    return attacked_states
```

**ä¸ºä»€ä¹ˆåœ¨ CPU ä¸Š**ï¼š
- å®¢æˆ·ç«¯å‚æ•°å·²ç»åœ¨ CPUï¼ˆä» `get_model_state(to_cpu=True)` è·å–ï¼‰
- ç»Ÿè®¡è®¡ç®—ï¼ˆmean, stdï¼‰åœ¨ CPU
- æ”»å‡»åº”ç”¨åœ¨ CPU

**æ€§èƒ½å½±å“**ï¼š
- ç»Ÿè®¡è®¡ç®—ï¼šO(n Ã— d)ï¼Œä½†åœ¨ CPU ä¸Šï¼Œçº¦ 0.1-0.5 ç§’
- å¯¹äºå°è§„æ¨¡å®éªŒï¼ˆ< 100 å®¢æˆ·ç«¯ï¼‰ï¼Œå¯æ¥å—

---

## ğŸš€ æ€§èƒ½ä¼˜åŒ–æœºä¼š

### é«˜ä¼˜å…ˆçº§ä¼˜åŒ–

#### 1. **é˜²å¾¡èšåˆç®—æ³• GPU åŠ é€Ÿ** â­â­â­

**ä¼˜åŒ–ä»·å€¼**ï¼šé«˜ï¼ˆä¸»è¦ç“¶é¢ˆï¼‰

**æ–¹æ¡ˆ**ï¼š

```python
def geometric_median_state_dicts_gpu(
    state_dicts: Sequence[Dict[str, torch.Tensor]],
    weights: Sequence[float] | None = None,
    device: torch.device = torch.device("cuda"),
    max_iters: int = 50,
    tol: float = 1e-6,
) -> Dict[str, torch.Tensor]:
    """GPU-accelerated geometric median computation."""

    # âœ… ç›´æ¥åœ¨ GPU ä¸Š flattenï¼ˆé¿å… CPU è½¬æ¢ï¼‰
    flat_states = torch.stack([
        flatten_state_dict(state).to(torch.float64).to(device)  # GPU
        for state in state_dicts
    ])

    weight_tensor = torch.tensor(weights, dtype=torch.float64, device=device)  # GPU
    median = (flat_states * weight_tensor.unsqueeze(1)).sum(dim=0)  # GPU

    eps = 1e-12
    for _ in range(max_iters):
        distances = torch.norm(flat_states - median, dim=1).clamp_min(eps)  # GPU å¹¶è¡Œ
        inverted = weight_tensor / distances  # GPU
        denominator = inverted.sum()

        if denominator < eps:
            break

        new_median = (flat_states * inverted.unsqueeze(1)).sum(dim=0) / denominator  # GPU
        shift = torch.norm(new_median - median).item()
        median = new_median

        if shift < tol:
            break

    # åªåœ¨æœ€åè½¬å› CPU
    median_cpu = median.to(torch.float32).cpu()
    return unflatten_state_dict(median_cpu, state_dicts[0])
```

**é¢„æœŸåŠ é€Ÿ**ï¼š
- å°æ¨¡å‹ï¼ˆLeNet, 44K å‚æ•°ï¼‰ï¼š1.5-2x åŠ é€Ÿ
- å¤§æ¨¡å‹ï¼ˆResNet, 11M å‚æ•°ï¼‰ï¼š5-10x åŠ é€Ÿ
- åŸå› ï¼šGPU å¹¶è¡Œè®¡ç®—è·ç¦»å’ŒåŠ æƒå’Œ

**å®æ–½éš¾ç‚¹**ï¼š
- éœ€è¦ä¿®æ”¹ `get_model_state()` ä¿ç•™ GPU å¼ é‡ï¼ˆæˆ–æ”¯æŒå¯é€‰å‚æ•°ï¼‰
- éœ€è¦ç®¡ç† GPU å†…å­˜ï¼ˆå¤šä¸ªå®¢æˆ·ç«¯å‚æ•°åŒæ—¶åœ¨ GPUï¼‰

#### 2. **Krum GPU åŠ é€Ÿ** â­â­

**ä¼˜åŒ–ä»·å€¼**ï¼šä¸­é«˜

**æ–¹æ¡ˆ**ï¼š

```python
def krum_aggregate_gpu(
    state_dicts: Sequence[Dict[str, torch.Tensor]],
    weights: Sequence[float],
    device: torch.device = torch.device("cuda"),
    num_malicious: int = 0,
    multi_krum: bool = False,
) -> Dict[str, torch.Tensor]:
    """GPU-accelerated Krum aggregation."""

    # âœ… åœ¨ GPU ä¸Š flatten
    vecs = torch.stack([
        flatten_state_dict(state).to(torch.float32).to(device)
        for state in state_dicts
    ])  # GPU tensor [n, d]

    n = len(state_dicts)
    f = min(num_malicious, n // 3)

    # âœ… GPU å¹¶è¡Œè®¡ç®—è·ç¦»çŸ©é˜µ
    distances = torch.cdist(vecs, vecs, p=2)  # GPU [n, n]

    # âœ… GPU å¹¶è¡Œæ’åºå’Œæ±‚å’Œ
    sorted_distances, _ = torch.sort(distances, dim=1)  # GPU
    n_select = max(1, n - f - 2)
    scores = sorted_distances[:, 1:n_select+1].sum(dim=1)  # GPUï¼Œå‘é‡åŒ–

    # Select best update(s)
    if multi_krum:
        m = max(1, n - f - 2)
        selected_indices = torch.argsort(scores)[:m]  # GPU
        # ... Multi-Krum averaging
    else:
        best_idx = torch.argmin(scores).item()  # åªè½¬æ¢ä¸€ä¸ªæ ‡é‡åˆ° CPU
        return clone_state_dict(state_dicts[best_idx])
```

**é¢„æœŸåŠ é€Ÿ**ï¼š
- è·ç¦»çŸ©é˜µè®¡ç®—ï¼š3-5x åŠ é€Ÿï¼ˆGPU å¹¶è¡Œï¼‰
- æ’åºï¼š2-3x åŠ é€Ÿ
- æ€»ä½“ï¼š3-4x åŠ é€Ÿ

#### 3. **å‚æ•°ç©ºé—´æ”»å‡» GPU åŠ é€Ÿ** â­

**ä¼˜åŒ–ä»·å€¼**ï¼šä½ï¼ˆæ”»å‡»é¢‘ç‡ä½ï¼Œå½±å“å°ï¼‰

**æ–¹æ¡ˆ**ï¼šç±»ä¼¼é˜²å¾¡æ–¹æ³•ï¼Œåœ¨ GPU ä¸Šè®¡ç®—ç»Ÿè®¡é‡

---

### ä¸­ä¼˜å…ˆçº§ä¼˜åŒ–

#### 4. **æ‰¹é‡æ¨¡å‹è¯„ä¼° GPU åŠ é€Ÿ** â­â­

**å½“å‰ç“¶é¢ˆ**ï¼š

æ¯ä¸ªå®¢æˆ·ç«¯è¯„ä¼° 2 æ¬¡ï¼ˆsync + localï¼‰ï¼Œä¸²è¡Œæ‰§è¡Œï¼š

```python
for client in clients:
    sync_metrics = client.evaluate(test_loader)  # GPU
    # ... training ...
    local_metrics = client.evaluate(test_loader)  # GPU
```

**ä¼˜åŒ–æ–¹æ¡ˆ**ï¼š

æ‰¹é‡è¯„ä¼°ï¼ˆå¦‚æœæµ‹è¯•é›†å¯ä»¥å…±äº«ï¼‰ï¼š

```python
# å°†å¤šä¸ªå®¢æˆ·ç«¯çš„æ¨¡å‹æ‰¹é‡åŒ–è¯„ä¼°
def batch_evaluate_models(models, test_loader, device):
    """Evaluate multiple models in parallel on the same data."""
    batch_results = []

    for inputs, targets in test_loader:
        inputs = inputs.to(device)
        targets = targets.to(device)

        # å¹¶è¡Œè¯„ä¼°å¤šä¸ªæ¨¡å‹
        for model in models:
            model.eval()
            with torch.no_grad():
                outputs = model(inputs)
                # ... æ”¶é›†ç»“æœ

    return batch_results
```

**é¢„æœŸåŠ é€Ÿ**ï¼š
- é€‚ç”¨äºå°æ¨¡å‹ï¼ˆå¯ä»¥åŒæ—¶æ”¾å¤šä¸ªåœ¨ GPUï¼‰
- 1.5-2x åŠ é€Ÿï¼ˆé€šè¿‡æ›´å¥½çš„ GPU åˆ©ç”¨ç‡ï¼‰

**å®æ–½éš¾ç‚¹**ï¼š
- éœ€è¦é‡æ„è¯„ä¼°é€»è¾‘
- GPU å†…å­˜é™åˆ¶ï¼ˆä¸èƒ½åŒæ—¶æ”¾å¤ªå¤šæ¨¡å‹ï¼‰

---

## ğŸ“Š å½“å‰æ€§èƒ½ç“¶é¢ˆåˆ†æ

åŸºäº 100 å®¢æˆ·ç«¯ï¼ŒLeNet (44K å‚æ•°)ï¼ŒMNIST çš„å…¸å‹å®éªŒï¼š

### æ¯è½®æ—¶é—´åˆ†è§£ï¼ˆå•æœåŠ¡å™¨ï¼Œ50 å®¢æˆ·ç«¯ï¼‰

| é˜¶æ®µ | å½“å‰è®¾å¤‡ | æ—¶é—´ | å æ¯” | å¯ä¼˜åŒ–ï¼Ÿ |
|------|---------|------|------|---------|
| å®¢æˆ·ç«¯è®­ç»ƒ (50x) | âœ… GPU | ~150s | 75% | âœ… å·²ä¼˜åŒ– |
| å®¢æˆ·ç«¯åŒæ­¥è¯„ä¼° (50x) | âœ… GPU | ~15s | 7.5% | å¯æ‰¹é‡åŒ– |
| å®¢æˆ·ç«¯æœ¬åœ°è¯„ä¼° (50x) | âœ… GPU | ~15s | 7.5% | å¯æ‰¹é‡åŒ– |
| æœåŠ¡å™¨èšåˆ (Geo Median) | âŒ CPU | ~5s | 2.5% | â­ å¯ GPU åŠ é€Ÿ |
| æœåŠ¡å™¨å…¨å±€è¯„ä¼° (1x) | âœ… GPU | ~0.5s | 0.25% | âœ… å·²ä¼˜åŒ– |
| å‚æ•°ä¼ è¾“ (CPUâ†”GPU) | N/A | ~5s | 2.5% | å¯å‡å°‘ |
| å…¶ä»–å¼€é”€ | N/A | ~10s | 5% | - |
| **æ€»è®¡** | - | **~200s** | **100%** | - |

### ç“¶é¢ˆè¯†åˆ«

1. **ä¸»è¦ç“¶é¢ˆ**ï¼šå®¢æˆ·ç«¯è®­ç»ƒï¼ˆ75%ï¼‰
   - âœ… å·²ç»åœ¨ GPU ä¸Šï¼Œå……åˆ†ä¼˜åŒ–
   - å¯ä»¥é€šè¿‡å¤š GPU å¹¶è¡Œå‡å°‘ï¼ˆå·²å®ç°ï¼‰

2. **æ¬¡è¦ç“¶é¢ˆ**ï¼šå®¢æˆ·ç«¯è¯„ä¼°ï¼ˆ15%ï¼‰
   - âœ… åœ¨ GPU ä¸Šï¼Œä½†å¯ä»¥æ‰¹é‡åŒ–

3. **å°ç“¶é¢ˆ**ï¼šæœåŠ¡å™¨èšåˆï¼ˆ2.5%ï¼‰
   - âŒ åœ¨ CPU ä¸Šï¼Œå¯ä»¥ GPU åŠ é€Ÿ
   - å¯¹äºå¤§æ¨¡å‹å½±å“æ›´å¤§

4. **å¯å¿½ç•¥**ï¼šå‚æ•°ä¼ è¾“ï¼ˆ2.5%ï¼‰
   - å¯¹äºå°æ¨¡å‹å½±å“å°
   - å¯¹äºå¤§æ¨¡å‹å¯èƒ½æˆä¸ºç“¶é¢ˆ

---

## ğŸ¯ ä¼˜åŒ–å»ºè®®æ€»ç»“

### ç«‹å³å®æ–½ï¼ˆé«˜æ€§ä»·æ¯”ï¼‰

1. **ä¿æŒç°çŠ¶**ï¼ˆå¯¹äºå°æ¨¡å‹ LeNet, 44K å‚æ•°ï¼‰ï¼š
   - å½“å‰ç“¶é¢ˆæ˜¯è®­ç»ƒæœ¬èº«ï¼ˆ75%ï¼‰ï¼Œå·²ç»åœ¨ GPU
   - èšåˆåªå  2.5%ï¼Œä¼˜åŒ–æ”¶ç›Šæœ‰é™
   - **å»ºè®®**ï¼šæ— éœ€ä¼˜åŒ–ï¼Œç°æœ‰å®ç°å·²è¶³å¤Ÿé«˜æ•ˆ

### ä¸­æœŸå®æ–½ï¼ˆå¤§æ¨¡å‹åœºæ™¯ï¼‰

2. **å¦‚æœä½¿ç”¨å¤§æ¨¡å‹ï¼ˆResNet, 11M+ å‚æ•°ï¼‰**ï¼š
   - èšåˆæ—¶é—´å¯èƒ½å¢åŠ åˆ° 10-30 ç§’ï¼ˆ5-15%ï¼‰
   - **å»ºè®®**ï¼šå®æ–½ Geometric Median GPU åŠ é€Ÿ
   - **é¢„æœŸæ”¶ç›Š**ï¼šæ¯è½®èŠ‚çœ 8-25 ç§’

3. **å¦‚æœå®¢æˆ·ç«¯æ•°é‡å¾ˆå¤šï¼ˆ500+ å®¢æˆ·ç«¯ï¼‰**ï¼š
   - Krum è·ç¦»è®¡ç®— O(nÂ²) æˆä¸ºç“¶é¢ˆ
   - **å»ºè®®**ï¼šå®æ–½ Krum GPU åŠ é€Ÿ
   - **é¢„æœŸæ”¶ç›Š**ï¼šæ¯è½®èŠ‚çœ 10-20 ç§’

### é•¿æœŸä¼˜åŒ–ï¼ˆå¯é€‰ï¼‰

4. **æ‰¹é‡è¯„ä¼°**ï¼š
   - é€‚ç”¨äºå°æ¨¡å‹ + æµ‹è¯•é›†å¯å…±äº«çš„åœºæ™¯
   - éœ€è¦é‡æ„ä»£ç 
   - **é¢„æœŸæ”¶ç›Š**ï¼šæ¯è½®èŠ‚çœ 10-15 ç§’

5. **å‡å°‘ CPU-GPU ä¼ è¾“**ï¼š
   - ä¿æŒå®¢æˆ·ç«¯å‚æ•°åœ¨ GPU ç›´åˆ°èšåˆå®Œæˆ
   - éœ€è¦ä»”ç»†ç®¡ç† GPU å†…å­˜
   - **é¢„æœŸæ”¶ç›Š**ï¼šæ¯è½®èŠ‚çœ 3-5 ç§’

---

## ğŸ’¡ å®æ–½ä¼˜å…ˆçº§å»ºè®®

### å½“å‰é¡¹ç›®ï¼ˆMNIST + LeNetï¼‰

**ç»“è®º**ï¼šâœ… **æ— éœ€ä¼˜åŒ–**

- å½“å‰å®ç°å·²ç»å¾ˆå¥½åœ°åˆ©ç”¨äº† GPUï¼ˆè®­ç»ƒã€è¯„ä¼°ï¼‰
- ç“¶é¢ˆåœ¨è®­ç»ƒæœ¬èº«ï¼ˆ75%ï¼‰ï¼Œå·²ç»åœ¨ GPU ä¸”å……åˆ†å¹¶è¡Œ
- èšåˆåªå  2.5%ï¼Œä¼˜åŒ–æ”¶ç›Š < 5%
- **å»ºè®®**ï¼šä¸“æ³¨äºå®éªŒå’Œè®ºæ–‡æ’°å†™

### æœªæ¥æ‰©å±•ï¼ˆCIFAR-10 + ResNetï¼‰

**å»ºè®®**ï¼šâœ… **å®æ–½ Geometric Median GPU åŠ é€Ÿ**

- é¢„æœŸèšåˆæ—¶é—´å¢åŠ åˆ° 10-30 ç§’ï¼ˆ5-15% å æ¯”ï¼‰
- GPU åŠ é€Ÿå¯èŠ‚çœ 8-25 ç§’/è½®
- 50 è½®å®éªŒå¯èŠ‚çœ 7-20 åˆ†é’Ÿ
- **å®æ–½éš¾åº¦**ï¼šä¸­ç­‰ï¼ˆ1-2 å¤©å¼€å‘ + æµ‹è¯•ï¼‰

---

## ğŸ“ ä»£ç å®æ–½å»ºè®®

### å¦‚æœéœ€è¦ GPU åŠ é€Ÿèšåˆï¼Œå¯ä»¥è¿™æ ·ä¿®æ”¹ï¼š

#### Step 1: ä¿®æ”¹ `Client.get_model_state()` æ”¯æŒ GPU è¿”å›

```python
def get_model_state(self, to_cpu: bool = True) -> Dict[str, torch.Tensor]:
    """Return a cloned copy of local model state."""
    state = clone_state_dict(self.model.state_dict())
    if to_cpu:
        state = {k: v.detach().cpu() for k, v in state.items()}
    return state
```

#### Step 2: ä¿®æ”¹ `Server.run_round()` ä¿ç•™ GPU å¼ é‡

```python
def run_round(self, clients, test_loader, round_idx):
    # æ”¶é›†å®¢æˆ·ç«¯çŠ¶æ€æ—¶ä¿ç•™åœ¨ GPU
    for client in clients:
        client_state = client.get_model_state(to_cpu=False)  # ä¿ç•™ GPU
        client_states.append(client_state)

    # åœ¨ GPU ä¸Šèšåˆ
    aggregated_state = self._aggregate_client_states_gpu(
        client_states, weights, self.device
    )
```

#### Step 3: å®ç° GPU ç‰ˆæœ¬çš„èšåˆå‡½æ•°

ï¼ˆè§ä¸Šæ–‡"ä¼˜åŒ–æœºä¼š"éƒ¨åˆ†çš„ä»£ç ï¼‰

---

## ğŸ” éªŒè¯æ–¹æ³•

### æ€§èƒ½æµ‹è¯•è„šæœ¬

```python
import time
import torch

# æµ‹è¯• CPU vs GPU èšåˆæ€§èƒ½
def benchmark_aggregation():
    # ç”Ÿæˆæµ‹è¯•æ•°æ®ï¼ˆæ¨¡æ‹Ÿ 100 å®¢æˆ·ç«¯ï¼Œ11M å‚æ•°ï¼‰
    n_clients = 100
    param_size = 11_000_000

    cpu_states = [torch.randn(param_size) for _ in range(n_clients)]
    gpu_states = [s.cuda() for s in cpu_states]

    # CPU ç‰ˆæœ¬
    start = time.time()
    result_cpu = geometric_median_state_dicts(cpu_states)
    cpu_time = time.time() - start

    # GPU ç‰ˆæœ¬
    start = time.time()
    result_gpu = geometric_median_state_dicts_gpu(gpu_states, device=torch.device("cuda"))
    gpu_time = time.time() - start

    print(f"CPU time: {cpu_time:.3f}s")
    print(f"GPU time: {gpu_time:.3f}s")
    print(f"Speedup: {cpu_time / gpu_time:.2f}x")
```

---

**æ–‡æ¡£ç‰ˆæœ¬**: v1.0
**æœ€åæ›´æ–°**: 2025-11-13
**ä½œè€…**: Multi-Server FL Team
