#!/usr/bin/env python3
"""
åˆ†æOursæ–¹æ³•è®­ç»ƒæ›²çº¿å¼‚å¸¸çš„åŸå› 
åŒ…æ‹¬ï¼šåˆæœŸä¸‹é™ã€ä¸­æœŸæŠ–åŠ¨ã€æœ«æœŸä¸‹é™
"""
import json
from pathlib import Path
import matplotlib.pyplot as plt
from matplotlib import rcParams
import numpy as np

def load_history(path):
    with open(path, 'r') as f:
        return json.load(f)

def analyze_training_anomalies():
    """åˆ†æè®­ç»ƒæ›²çº¿çš„å¼‚å¸¸ç°è±¡"""

    history_path = "runs/ours/20251106-212741-350231_ours_100r_noise_random_retest/history.json"
    history = load_history(history_path)

    # æå–å…³é”®æŒ‡æ ‡
    rounds = []
    benign_acc = []
    accepted_rate = []
    similarity = []
    nan_detected = []
    threshold = []

    for entry in history:
        r = entry['round']
        agg = entry['aggregated']

        rounds.append(r)
        benign_acc.append(agg.get('benign_test_accuracy_mean', 0))
        accepted_rate.append(agg.get('benign_accepted_mean', 0))

        # Similarityå¯èƒ½æ˜¯nan
        sim = agg.get('benign_similarity_mean', 0)
        if isinstance(sim, float) and not np.isnan(sim):
            similarity.append(sim)
        else:
            similarity.append(None)

        nan_detected.append(agg.get('benign_nan_detected_mean', 0))

    # è®¡ç®—åŠ¨æ€é˜ˆå€¼ (gamma=1.0, kappa=0.01)
    gamma = 1.0
    kappa = 0.01
    threshold = [gamma * np.exp(-kappa * r) for r in rounds]

    print("=" * 80)
    print("è®­ç»ƒæ›²çº¿å¼‚å¸¸åˆ†ææŠ¥å‘Š")
    print("=" * 80)

    # 1. åˆæœŸä¸‹é™åˆ†æ (Round 1-5)
    print("\nã€é—®é¢˜1ã€‘åˆæœŸä¸‹é™ (Round 1-5: 18.56% â†’ 11.44%)")
    print("-" * 80)
    print("åŸå› åˆ†æ:")
    print("  1. æ¶æ„æ”»å‡»çš„å½±å“:")
    print(f"     - 20%æ¶æ„å®¢æˆ·ç«¯ (noiseæ”»å‡», std=0.5)")
    print(f"     - 10%æ¶æ„æœåŠ¡å™¨ (randomæ”»å‡», noise_scale=5.0)")
    print("\n  2. BALANCEéªŒè¯æœºåˆ¶çš„é€‚åº”è¿‡ç¨‹:")
    for i in range(5):
        sim_str = f"{similarity[i]:.4f}" if similarity[i] is not None else "N/A"
        print(f"     Round {i+1}: Accepted={accepted_rate[i]:.2%}, Similarity={sim_str}, Threshold={threshold[i]:.4f}")

    print("\n  3. é—®é¢˜:")
    print("     - Round 1: 80.8%çš„æ›´æ–°è¢«æ¥å—ï¼Œä½†æœåŠ¡å™¨èšåˆåŒ…å«æ¶æ„æ›´æ–°")
    print("     - Round 2-5: Accepted Rateä¸‹é™åˆ°61.1%â†’98.6%ï¼Œå®¢æˆ·ç«¯åœ¨å­¦ä¹ æ‹’ç»å¯ç–‘æ›´æ–°")
    print("     - ä½†æ‹’ç»ç‡æé«˜åè€Œå¯¼è‡´å‡†ç¡®ç‡ä¸‹é™ â†’ è¯´æ˜Geometric Medianåœ¨åˆæœŸæœªèƒ½æœ‰æ•ˆè¿‡æ»¤æ¶æ„æ›´æ–°")

    # 2. ä¸­æœŸæŠ–åŠ¨åˆ†æ
    print("\nã€é—®é¢˜2ã€‘ä¸­æœŸæŠ–åŠ¨ (Round 10-50)")
    print("-" * 80)
    acc_std_mid = np.std([benign_acc[i] for i in range(10, 50)])
    print(f"  å‡†ç¡®ç‡æ ‡å‡†å·®: {acc_std_mid:.4f}")
    print("  åŸå› åˆ†æ:")
    print("    - BALANCEé˜ˆå€¼éšè½®æ¬¡æŒ‡æ•°è¡°å‡: threshold = 1.0 * exp(-0.01 * round)")
    print(f"    - Round 10: threshold = {threshold[9]:.4f}")
    print(f"    - Round 50: threshold = {threshold[49]:.4f}")
    print("    - é˜ˆå€¼å˜åŒ–å¯¼è‡´æ¥å—/æ‹’ç»å†³ç­–ä¸ç¨³å®š")
    print("    - Non-IIDæ•°æ® (alpha=0.5) å¯¼è‡´å®¢æˆ·ç«¯æ¢¯åº¦æ–¹å·®è¾ƒå¤§")

    # 3. æœ«æœŸå´©æºƒåˆ†æ (Round 96-100)
    print("\nã€é—®é¢˜3ã€‘æœ«æœŸå‡†ç¡®ç‡å´©æºƒ (Round 96-100: 87.03% â†’ 78.26%)")
    print("-" * 80)
    print("å…³é”®è¯æ®:")
    for i in range(95, 100):
        nan_rate = nan_detected[i]
        acc = benign_acc[i]
        sim = similarity[i]
        accepted = accepted_rate[i]
        print(f"  Round {i+1}: Acc={acc:.4f}, NaNæ£€æµ‹={nan_rate:.4f}, Similarity={sim if sim else 'NaN'}, Accepted={accepted:.4f}")

    print("\n  ä¸¥é‡é—®é¢˜:")
    print("    1. Round 97å¼€å§‹å‡ºç°NaN: NaNæ£€æµ‹ç‡ä»0%å‡è‡³6.88%")
    print("    2. Round 97: Similarityçªå˜ä¸º14.28 (æ­£å¸¸åº”è¯¥<1.0)")
    print("    3. Round 98-100: Similarityå˜æˆNaN")
    print("    4. NaNæ£€æµ‹ç‡æŒç»­ä¸Šå‡: 6.88% -> 9.23% -> 11.41%")
    print("    5. å‡†ç¡®ç‡æš´è·Œ: 87.03% -> 78.26%")

    print("\n  æ ¹æœ¬åŸå› :")
    print("    æ¨¡å‹å‚æ•°å‡ºç°æ•°å€¼ä¸ç¨³å®š (NaN/Inf)")
    print("    å¯èƒ½åŸå› :")
    print("       a) å­¦ä¹ ç‡0.01åœ¨åæœŸè¿‡å¤§,å¯¼è‡´æ¢¯åº¦çˆ†ç‚¸")
    print("       b) æ¶æ„æ”»å‡»ç´¯ç§¯æ•ˆåº”")
    print("       c) Geometric Medianè®¡ç®—æ—¶çš„æ•°å€¼è¯¯å·®ç´¯ç§¯")
    print("       d) æŸäº›å®¢æˆ·ç«¯çš„æç«¯æ¢¯åº¦æœªè¢«æ­£ç¡®clip")

    # ç»˜åˆ¶è¯¦ç»†è¯Šæ–­å›¾
    plot_diagnostic_charts(rounds, benign_acc, accepted_rate, similarity, nan_detected, threshold)

    # ç»™å‡ºå»ºè®®
    print("\n" + "=" * 80)
    print("ğŸ”§ æ”¹è¿›å»ºè®®")
    print("=" * 80)
    print("\n1. è§£å†³åˆæœŸä¸‹é™:")
    print("   - å¢å¼ºGeometric Mediançš„é²æ£’æ€§ (è°ƒæ•´max_iterå‚æ•°)")
    print("   - ä½¿ç”¨warmupé˜¶æ®µï¼ŒåˆæœŸä¸è¿›è¡Œå®¢æˆ·ç«¯éªŒè¯")
    print("   - è€ƒè™‘ä½¿ç”¨Krumæˆ–Trimmed Meanç­‰å…¶ä»–é²æ£’èšåˆå™¨")

    print("\n2. å‡å°‘ä¸­æœŸæŠ–åŠ¨:")
    print("   - è°ƒæ•´BALANCEå‚æ•°: å‡å°kappa (å¦‚0.005)ï¼Œå‡ç¼“é˜ˆå€¼è¡°å‡")
    print("   - ä½¿ç”¨moving averageå¹³æ»‘å®¢æˆ·ç«¯æ›´æ–°")
    print("   - å¢åŠ local_epochsä»¥æé«˜æœ¬åœ°æ›´æ–°è´¨é‡")

    print("\n3. ä¿®å¤æœ«æœŸå´©æºƒ (æœ€é‡è¦!):")
    print("   âœ… æ·»åŠ æ¢¯åº¦è£å‰ª: torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)")
    print("   âœ… ä½¿ç”¨å­¦ä¹ ç‡è¡°å‡: lr_scheduler (å¦‚CosineAnnealing)")
    print("   âœ… å¢å¼ºNaNæ£€æµ‹å’Œå¤„ç†: æ£€æµ‹åˆ°NaNåå›æ»šåˆ°ä¸Šä¸€è½®çš„æ¨¡å‹")
    print("   âœ… é™åˆ¶å‚æ•°æ›´æ–°å¹…åº¦: æ£€æµ‹å¹¶æ‹’ç»å¼‚å¸¸å¤§çš„æ›´æ–°")
    print("   âœ… ä½¿ç”¨æ··åˆç²¾åº¦è®­ç»ƒ (FP16) å¯èƒ½ä¼šå¼•å…¥æ•°å€¼é—®é¢˜ï¼Œæ”¹ç”¨FP32")

    print("\n4. æ•°æ®å’Œè¶…å‚æ•°:")
    print("   - é™ä½å­¦ä¹ ç‡: 0.01 â†’ 0.001 (åœ¨åæœŸ)")
    print("   - å¢åŠ batch_size: 64 â†’ 128 (å‡å°‘æ¢¯åº¦æ–¹å·®)")
    print("   - è°ƒæ•´alpha: 0.5 â†’ 1.0 (å‡å°‘æ•°æ®å¼‚æ„æ€§)")

def plot_diagnostic_charts(rounds, benign_acc, accepted_rate, similarity, nan_detected, threshold):
    """ç»˜åˆ¶è¯¦ç»†è¯Šæ–­å›¾"""
    rcParams["font.family"] = "Times New Roman"

    fig, axes = plt.subplots(2, 2, figsize=(14, 10))
    fig.suptitle("Training Curve Diagnostic Analysis", fontsize=16, fontweight='bold')

    # 1. å‡†ç¡®ç‡æ›²çº¿ + å…³é”®äº‹ä»¶æ ‡æ³¨
    ax1 = axes[0, 0]
    ax1.plot(rounds, benign_acc, 'b-', linewidth=2, label='Benign Test Accuracy')
    ax1.axvspan(1, 5, alpha=0.2, color='red', label='Phase 1: Initial Drop')
    ax1.axvspan(10, 50, alpha=0.2, color='orange', label='Phase 2: Oscillation')
    ax1.axvspan(96, 100, alpha=0.2, color='darkred', label='Phase 3: Collapse')
    ax1.axhline(y=max(benign_acc), color='g', linestyle='--', linewidth=1, label=f'Peak: {max(benign_acc):.4f}')
    ax1.set_xlabel('Round', fontsize=12)
    ax1.set_ylabel('Accuracy', fontsize=12)
    ax1.set_title('Benign Test Accuracy with Problem Phases', fontsize=13, fontweight='bold')
    ax1.legend(fontsize=9)
    ax1.grid(True, alpha=0.3)

    # 2. æ¥å—ç‡ vs é˜ˆå€¼
    ax2 = axes[0, 1]
    ax2.plot(rounds, accepted_rate, 'g-', linewidth=2, label='Accepted Rate')
    ax2.plot(rounds, threshold, 'r--', linewidth=2, label='Threshold (Î³Â·exp(-ÎºÂ·t))')
    ax2.set_xlabel('Round', fontsize=12)
    ax2.set_ylabel('Rate', fontsize=12)
    ax2.set_title('BALANCE Acceptance Rate vs Dynamic Threshold', fontsize=13, fontweight='bold')
    ax2.legend(fontsize=10)
    ax2.grid(True, alpha=0.3)

    # 3. Similarity (è¿‡æ»¤NaN)
    ax3 = axes[1, 0]
    valid_rounds = [r for r, s in zip(rounds, similarity) if s is not None]
    valid_similarity = [s for s in similarity if s is not None]
    ax3.plot(valid_rounds, valid_similarity, 'purple', linewidth=2, marker='o', markersize=3)
    ax3.set_xlabel('Round', fontsize=12)
    ax3.set_ylabel('Similarity Ratio', fontsize=12)
    ax3.set_title('Client-Server Update Similarity (NaN excluded)', fontsize=13, fontweight='bold')
    ax3.set_yscale('log')  # ä½¿ç”¨å¯¹æ•°åæ ‡ï¼Œå› ä¸ºå€¼èŒƒå›´å¾ˆå¤§
    ax3.grid(True, alpha=0.3)

    # 4. NaNæ£€æµ‹ç‡
    ax4 = axes[1, 1]
    ax4.plot(rounds, nan_detected, 'r-', linewidth=2, marker='x', markersize=4)
    ax4.fill_between(rounds, 0, nan_detected, alpha=0.3, color='red')
    ax4.set_xlabel('Round', fontsize=12)
    ax4.set_ylabel('NaN Detection Rate', fontsize=12)
    ax4.set_title('NaN/Inf Detection in Client Updates', fontsize=13, fontweight='bold')
    ax4.grid(True, alpha=0.3)

    # æ ‡æ³¨æœ«æœŸå´©æºƒç‚¹
    collapse_start = 96
    ax4.axvline(x=collapse_start, color='darkred', linestyle='--', linewidth=2, label='Collapse Start')
    ax4.legend(fontsize=10)

    plt.tight_layout()
    output_path = Path("outputs/diagnostic_analysis.png")
    output_path.parent.mkdir(parents=True, exist_ok=True)
    plt.savefig(output_path, dpi=300, bbox_inches='tight')
    plt.close()

    print(f"\nğŸ“Š è¯¦ç»†è¯Šæ–­å›¾å·²ä¿å­˜åˆ°: {output_path}")

if __name__ == "__main__":
    analyze_training_anomalies()
